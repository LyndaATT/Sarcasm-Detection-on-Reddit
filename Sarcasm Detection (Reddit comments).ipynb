{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Sarcasm on Reddit comments\n",
    "##### Lynda Attouche & Sami Benyahia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:11.112004Z",
     "iopub.status.busy": "2021-12-28T18:49:11.111747Z",
     "iopub.status.idle": "2021-12-28T18:49:11.123651Z",
     "shell.execute_reply": "2021-12-28T18:49:11.122602Z",
     "shell.execute_reply.started": "2021-12-28T18:49:11.111975Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "# word cloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# numeric + string \n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "# Regular Expression for text cleaning\n",
    "import re\n",
    "\n",
    "# nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# word2vec\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "\n",
    "#bert \n",
    "import transformers\n",
    "import torch\n",
    "import plotly.express as px\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing as kprocessing\n",
    "\n",
    "\n",
    "# keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import MaxPooling1D,GlobalMaxPooling1D,Conv1D, Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from keras import callbacks\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer \n",
    "from sklearn.metrics import roc_auc_score, accuracy_score,roc_curve, auc, plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:11.126261Z",
     "iopub.status.busy": "2021-12-28T18:49:11.125548Z",
     "iopub.status.idle": "2021-12-28T18:49:14.870211Z",
     "shell.execute_reply": "2021-12-28T18:49:14.869306Z",
     "shell.execute_reply.started": "2021-12-28T18:49:11.126222Z"
    }
   },
   "outputs": [],
   "source": [
    "#loading data \n",
    "df_train = pd.read_csv(\"/kaggle/input/sarcasm/train-balanced-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:14.872014Z",
     "iopub.status.busy": "2021-12-28T18:49:14.87166Z",
     "iopub.status.idle": "2021-12-28T18:49:14.885146Z",
     "shell.execute_reply": "2021-12-28T18:49:14.884493Z",
     "shell.execute_reply.started": "2021-12-28T18:49:14.871973Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:14.888036Z",
     "iopub.status.busy": "2021-12-28T18:49:14.887211Z",
     "iopub.status.idle": "2021-12-28T18:49:14.994336Z",
     "shell.execute_reply": "2021-12-28T18:49:14.993539Z",
     "shell.execute_reply.started": "2021-12-28T18:49:14.887989Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:14.995967Z",
     "iopub.status.busy": "2021-12-28T18:49:14.995655Z",
     "iopub.status.idle": "2021-12-28T18:49:15.00182Z",
     "shell.execute_reply": "2021-12-28T18:49:15.001017Z",
     "shell.execute_reply.started": "2021-12-28T18:49:14.99593Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:15.004097Z",
     "iopub.status.busy": "2021-12-28T18:49:15.003533Z",
     "iopub.status.idle": "2021-12-28T18:49:15.013053Z",
     "shell.execute_reply": "2021-12-28T18:49:15.011971Z",
     "shell.execute_reply.started": "2021-12-28T18:49:15.004058Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:15.015038Z",
     "iopub.status.busy": "2021-12-28T18:49:15.014523Z",
     "iopub.status.idle": "2021-12-28T18:49:15.625424Z",
     "shell.execute_reply": "2021-12-28T18:49:15.623629Z",
     "shell.execute_reply.started": "2021-12-28T18:49:15.014997Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:15.626623Z",
     "iopub.status.busy": "2021-12-28T18:49:15.626404Z",
     "iopub.status.idle": "2021-12-28T18:49:15.647199Z",
     "shell.execute_reply": "2021-12-28T18:49:15.646499Z",
     "shell.execute_reply.started": "2021-12-28T18:49:15.626582Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:15.650699Z",
     "iopub.status.busy": "2021-12-28T18:49:15.650489Z",
     "iopub.status.idle": "2021-12-28T18:49:15.663705Z",
     "shell.execute_reply": "2021-12-28T18:49:15.662667Z",
     "shell.execute_reply.started": "2021-12-28T18:49:15.650674Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:15.665926Z",
     "iopub.status.busy": "2021-12-28T18:49:15.665528Z",
     "iopub.status.idle": "2021-12-28T18:49:15.837093Z",
     "shell.execute_reply": "2021-12-28T18:49:15.836355Z",
     "shell.execute_reply.started": "2021-12-28T18:49:15.665888Z"
    }
   },
   "outputs": [],
   "source": [
    "cum = df_train['label'].value_counts().to_frame()\n",
    "cum['comment'] = cum.index\n",
    "cumfig, ax = plt.subplots(figsize=(5,5))\n",
    "sn.barplot(data=cum,x='comment',y='label',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of sarcastic and no sarcastic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:15.838672Z",
     "iopub.status.busy": "2021-12-28T18:49:15.838425Z",
     "iopub.status.idle": "2021-12-28T18:49:16.397071Z",
     "shell.execute_reply": "2021-12-28T18:49:16.396399Z",
     "shell.execute_reply.started": "2021-12-28T18:49:15.838639Z"
    }
   },
   "outputs": [],
   "source": [
    "sn.boxplot(x= df_train.loc[df_train['label'] == 1, 'comment'].str.len()).set(title = 'Length of Sarcastic Comments', xlabel = 'Length')\n",
    "sn.despine(offset=5, trim=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:16.400047Z",
     "iopub.status.busy": "2021-12-28T18:49:16.398341Z",
     "iopub.status.idle": "2021-12-28T18:49:16.985015Z",
     "shell.execute_reply": "2021-12-28T18:49:16.984337Z",
     "shell.execute_reply.started": "2021-12-28T18:49:16.400017Z"
    }
   },
   "outputs": [],
   "source": [
    "sn.boxplot(x= df_train.loc[df_train['label'] == 0, 'comment'].str.len()).set(title = 'Length of No Sarcastic Comments', xlabel = 'Length')\n",
    "sn.despine(offset=5, trim=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:16.986482Z",
     "iopub.status.busy": "2021-12-28T18:49:16.986201Z",
     "iopub.status.idle": "2021-12-28T18:49:17.556151Z",
     "shell.execute_reply": "2021-12-28T18:49:17.555457Z",
     "shell.execute_reply.started": "2021-12-28T18:49:16.986445Z"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='grey', stopwords = STOPWORDS,\n",
    "                max_words = 500, max_font_size = 100, \n",
    "                random_state = 17, width=800, height=400)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "wordcloud.generate(str(df_train.loc[df_train['label'] == 1, 'comment']))\n",
    "plt.grid(b= False)\n",
    "plt.imshow(wordcloud);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:17.557738Z",
     "iopub.status.busy": "2021-12-28T18:49:17.557343Z",
     "iopub.status.idle": "2021-12-28T18:49:17.592068Z",
     "shell.execute_reply": "2021-12-28T18:49:17.591271Z",
     "shell.execute_reply.started": "2021-12-28T18:49:17.557697Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns={'author','date','created_utc','subreddit','score','ups','downs','parent_comment'})\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text (comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:17.598058Z",
     "iopub.status.busy": "2021-12-28T18:49:17.596027Z",
     "iopub.status.idle": "2021-12-28T18:49:17.617441Z",
     "shell.execute_reply": "2021-12-28T18:49:17.616651Z",
     "shell.execute_reply.started": "2021-12-28T18:49:17.598019Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading contractions\n",
    "contractions = pd.read_csv(\"../input/d/ishivinal/contractions/contractions.csv\")\n",
    "contractions.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:17.622591Z",
     "iopub.status.busy": "2021-12-28T18:49:17.619776Z",
     "iopub.status.idle": "2021-12-28T18:49:17.635803Z",
     "shell.execute_reply": "2021-12-28T18:49:17.634173Z",
     "shell.execute_reply.started": "2021-12-28T18:49:17.622549Z"
    }
   },
   "outputs": [],
   "source": [
    "# emojis\n",
    "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
    "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
    "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
    "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
    "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
    "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:17.643981Z",
     "iopub.status.busy": "2021-12-28T18:49:17.643299Z",
     "iopub.status.idle": "2021-12-28T18:49:17.660732Z",
     "shell.execute_reply": "2021-12-28T18:49:17.659774Z",
     "shell.execute_reply.started": "2021-12-28T18:49:17.643916Z"
    }
   },
   "outputs": [],
   "source": [
    "# test of contractions\n",
    "word = \"isn't\"\n",
    "ww = word in contractions.Contraction.values\n",
    "contractions[contractions.Contraction==word].Meaning.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:17.66573Z",
     "iopub.status.busy": "2021-12-28T18:49:17.66531Z",
     "iopub.status.idle": "2021-12-28T18:49:17.675245Z",
     "shell.execute_reply": "2021-12-28T18:49:17.674623Z",
     "shell.execute_reply.started": "2021-12-28T18:49:17.665693Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleaning_text(s):\n",
    "    s = str(s).lower().strip()\n",
    "    s = \" \".join([contractions[contractions.Contraction==word].Meaning.values[0] if word in contractions.Contraction.values else word for word in s.split()])\n",
    "    s = \" \".join(['' if word in emojis.keys() else word for word in s.split()])\n",
    "\n",
    "    # removing \\n\n",
    "    sss = '\\n'\n",
    "    s = re.sub(sss, '', s)\n",
    "    # put spaces before & after punctuations to make words seprate\n",
    "    s = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-]\", \"\", s)\n",
    "    # Remove >=2 continues spaces with 1 space.\n",
    "    s = re.sub('[ ]{2,}', ' ', s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:17.679141Z",
     "iopub.status.busy": "2021-12-28T18:49:17.676354Z",
     "iopub.status.idle": "2021-12-28T18:49:25.056319Z",
     "shell.execute_reply": "2021-12-28T18:49:25.055473Z",
     "shell.execute_reply.started": "2021-12-28T18:49:17.679108Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_train.comment = df_train.comment.apply(cleaning_text)\n",
    "#On utilise un module de serialization pour accelerer le preprocessing\n",
    "!pip3 install pickle5\n",
    "path_to_file = '../input/preproquick/clean_text.pkl'\n",
    "\n",
    "import pickle5 as p\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open(path_to_file, \"rb\") as fh:\n",
    "    data = p.load(fh)\n",
    "\n",
    "df_train = data\n",
    "\n",
    "\n",
    "comments = df_train['comment'].values\n",
    "labels = df_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:25.058419Z",
     "iopub.status.busy": "2021-12-28T18:49:25.058155Z",
     "iopub.status.idle": "2021-12-28T18:49:25.063704Z",
     "shell.execute_reply": "2021-12-28T18:49:25.063036Z",
     "shell.execute_reply.started": "2021-12-28T18:49:25.05838Z"
    }
   },
   "outputs": [],
   "source": [
    "comments[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:25.065169Z",
     "iopub.status.busy": "2021-12-28T18:49:25.064917Z",
     "iopub.status.idle": "2021-12-28T18:49:25.07781Z",
     "shell.execute_reply": "2021-12-28T18:49:25.07712Z",
     "shell.execute_reply.started": "2021-12-28T18:49:25.065137Z"
    }
   },
   "outputs": [],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:25.079374Z",
     "iopub.status.busy": "2021-12-28T18:49:25.079191Z",
     "iopub.status.idle": "2021-12-28T18:49:25.094073Z",
     "shell.execute_reply": "2021-12-28T18:49:25.093299Z",
     "shell.execute_reply.started": "2021-12-28T18:49:25.079353Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:25.095931Z",
     "iopub.status.busy": "2021-12-28T18:49:25.095543Z",
     "iopub.status.idle": "2021-12-28T18:49:25.102852Z",
     "shell.execute_reply": "2021-12-28T18:49:25.102139Z",
     "shell.execute_reply.started": "2021-12-28T18:49:25.095897Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = df_train[800000:]\n",
    "df_train_w = df_train[:800000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:25.109242Z",
     "iopub.status.busy": "2021-12-28T18:49:25.108731Z",
     "iopub.status.idle": "2021-12-28T18:49:25.115923Z",
     "shell.execute_reply": "2021-12-28T18:49:25.115141Z",
     "shell.execute_reply.started": "2021-12-28T18:49:25.109208Z"
    }
   },
   "outputs": [],
   "source": [
    "#On recupere le model pretrained de google\n",
    "#nlp = gensim_api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:25.117948Z",
     "iopub.status.busy": "2021-12-28T18:49:25.117338Z",
     "iopub.status.idle": "2021-12-28T18:49:30.503794Z",
     "shell.execute_reply": "2021-12-28T18:49:30.503Z",
     "shell.execute_reply.started": "2021-12-28T18:49:25.11791Z"
    }
   },
   "outputs": [],
   "source": [
    "#On sépare chacun des mots de chaque commentaire dans un tableau\n",
    "corpus = df_train_w[\"comment\"]\n",
    "lst_corpus = []\n",
    "for string in corpus:\n",
    "    lst_words = string.split()\n",
    "    lst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, len(lst_words), 1)]\n",
    "    lst_corpus.append(lst_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:49:30.505564Z",
     "iopub.status.busy": "2021-12-28T18:49:30.505308Z",
     "iopub.status.idle": "2021-12-28T18:51:10.699825Z",
     "shell.execute_reply": "2021-12-28T18:51:10.699082Z",
     "shell.execute_reply.started": "2021-12-28T18:49:30.50553Z"
    }
   },
   "outputs": [],
   "source": [
    "#On crée notre propre modele au lieu d'utiliser le pre-trained ci dessus\n",
    "nlp = gensim.models.word2vec.Word2Vec(lst_corpus, vector_size=300,window=8, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:51:10.701576Z",
     "iopub.status.busy": "2021-12-28T18:51:10.70131Z",
     "iopub.status.idle": "2021-12-28T18:51:10.733377Z",
     "shell.execute_reply": "2021-12-28T18:51:10.732774Z",
     "shell.execute_reply.started": "2021-12-28T18:51:10.701541Z"
    }
   },
   "outputs": [],
   "source": [
    "#On transforme les mots de notre corpus en vecteur à l'aide du model que l'on a crée \n",
    "vocab = list(nlp.wv.key_to_index)\n",
    "X = nlp.wv[vocab[:5000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:51:10.735703Z",
     "iopub.status.busy": "2021-12-28T18:51:10.735217Z",
     "iopub.status.idle": "2021-12-28T18:52:29.368037Z",
     "shell.execute_reply": "2021-12-28T18:52:29.367444Z",
     "shell.execute_reply.started": "2021-12-28T18:51:10.735667Z"
    }
   },
   "outputs": [],
   "source": [
    "#TSNE permet de réduire la dimension pour passer à des points en 2D\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:52:29.369981Z",
     "iopub.status.busy": "2021-12-28T18:52:29.369488Z",
     "iopub.status.idle": "2021-12-28T18:52:29.561298Z",
     "shell.execute_reply": "2021-12-28T18:52:29.56045Z",
     "shell.execute_reply.started": "2021-12-28T18:52:29.369946Z"
    }
   },
   "outputs": [],
   "source": [
    "#On crée un dataframe avec chaque mot et sa representation vectorielle (les 5000 mots les plus utilisés)\n",
    "dfW2V = pd.DataFrame(X_tsne, index=vocab[:5000], columns=['x', 'y'])\n",
    "name = []\n",
    "for word, pos in dfW2V.iterrows():\n",
    "    name.append(word)\n",
    "dfW2V[\"name\"]= name\n",
    "dfW2V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:52:29.562905Z",
     "iopub.status.busy": "2021-12-28T18:52:29.562674Z",
     "iopub.status.idle": "2021-12-28T18:52:30.384154Z",
     "shell.execute_reply": "2021-12-28T18:52:30.383468Z",
     "shell.execute_reply.started": "2021-12-28T18:52:29.562875Z"
    }
   },
   "outputs": [],
   "source": [
    "#Representation des 500 mots les plus courants selon leurs coordonnées\n",
    "\n",
    "fig = px.scatter(dfW2V[:500], x=\"x\", y=\"y\", text =\"name\", size_max=100)\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(title_text='Representation des mots', title_x=0.5)\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:52:30.385648Z",
     "iopub.status.busy": "2021-12-28T18:52:30.385298Z",
     "iopub.status.idle": "2021-12-28T18:52:30.840301Z",
     "shell.execute_reply": "2021-12-28T18:52:30.83959Z",
     "shell.execute_reply.started": "2021-12-28T18:52:30.385594Z"
    }
   },
   "outputs": [],
   "source": [
    "#BERT ne fonctionne que pour les  commentaires de moins de 512 caracteres on supprime donc les commentaires plus longs\n",
    "df_train_b = df_train\n",
    "indexNames = df_train_b[df_train_b[\"comment\"].map(len) > 512 ].index\n",
    "indexNames\n",
    "df_train_b = df_train_b.drop(indexNames)\n",
    "df_trainX = df_train_b[:1000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:52:30.842001Z",
     "iopub.status.busy": "2021-12-28T18:52:30.841755Z",
     "iopub.status.idle": "2021-12-28T18:52:53.146967Z",
     "shell.execute_reply": "2021-12-28T18:52:53.146207Z",
     "shell.execute_reply.started": "2021-12-28T18:52:30.841966Z"
    }
   },
   "outputs": [],
   "source": [
    "## On recupere un modele pré-entrainé de BERT\n",
    "##DistilBert est une version plus petite mais bien plus rapide de BERT\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "model_class, tokenizer_class, pretrained_weights = (transformers.DistilBertModel, transformers.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:52:53.148381Z",
     "iopub.status.busy": "2021-12-28T18:52:53.148134Z",
     "iopub.status.idle": "2021-12-28T18:52:53.589049Z",
     "shell.execute_reply": "2021-12-28T18:52:53.588347Z",
     "shell.execute_reply.started": "2021-12-28T18:52:53.148336Z"
    }
   },
   "outputs": [],
   "source": [
    "#On tokenize les phrases pour mieux convenir au modele de BERT\n",
    "tokenized = df_trainX[\"comment\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, padding = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:52:53.590947Z",
     "iopub.status.busy": "2021-12-28T18:52:53.590166Z",
     "iopub.status.idle": "2021-12-28T18:52:53.601751Z",
     "shell.execute_reply": "2021-12-28T18:52:53.600929Z",
     "shell.execute_reply.started": "2021-12-28T18:52:53.590906Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:52:53.604485Z",
     "iopub.status.busy": "2021-12-28T18:52:53.603711Z",
     "iopub.status.idle": "2021-12-28T18:52:53.631334Z",
     "shell.execute_reply": "2021-12-28T18:52:53.630381Z",
     "shell.execute_reply.started": "2021-12-28T18:52:53.604435Z"
    }
   },
   "outputs": [],
   "source": [
    "#On applique un padding sur toutes les phrases pour qu'elle soit de meme taille puis on les represente sous la forme d'un\n",
    "# 2-d array car c'est selon le guide que j'ai suivi bien plus rapide que de traiter une liste de liste de taille variable.\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:52:53.632949Z",
     "iopub.status.busy": "2021-12-28T18:52:53.632532Z",
     "iopub.status.idle": "2021-12-28T18:52:53.643348Z",
     "shell.execute_reply": "2021-12-28T18:52:53.642657Z",
     "shell.execute_reply.started": "2021-12-28T18:52:53.632912Z"
    }
   },
   "outputs": [],
   "source": [
    "#On applique un masque pour empêcher de créer de la confusion dans le modèle à cause du padding\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:52:53.646872Z",
     "iopub.status.busy": "2021-12-28T18:52:53.646183Z",
     "iopub.status.idle": "2021-12-28T18:54:41.482977Z",
     "shell.execute_reply": "2021-12-28T18:54:41.482232Z",
     "shell.execute_reply.started": "2021-12-28T18:52:53.646833Z"
    }
   },
   "outputs": [],
   "source": [
    "#On utilise le modèle pré-entrainé pour créer un embedding de chaque phrase\n",
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:54:41.484458Z",
     "iopub.status.busy": "2021-12-28T18:54:41.4842Z",
     "iopub.status.idle": "2021-12-28T18:54:41.490879Z",
     "shell.execute_reply": "2021-12-28T18:54:41.488591Z",
     "shell.execute_reply.started": "2021-12-28T18:54:41.484425Z"
    }
   },
   "outputs": [],
   "source": [
    "#On garde seulement la partie de l'output qui correspond à l'embedding de la phrase entiere \n",
    "embedding = last_hidden_states[0][:,0,:].numpy()\n",
    "labels = df_trainX[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:54:41.492691Z",
     "iopub.status.busy": "2021-12-28T18:54:41.492118Z",
     "iopub.status.idle": "2021-12-28T18:54:41.503924Z",
     "shell.execute_reply": "2021-12-28T18:54:41.503182Z",
     "shell.execute_reply.started": "2021-12-28T18:54:41.492649Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:54:41.506066Z",
     "iopub.status.busy": "2021-12-28T18:54:41.505446Z",
     "iopub.status.idle": "2021-12-28T18:54:55.238486Z",
     "shell.execute_reply": "2021-12-28T18:54:55.237675Z",
     "shell.execute_reply.started": "2021-12-28T18:54:41.506026Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words='english')\n",
    " \n",
    "data_train= vectorizer.fit_transform(df_train.comment)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:54:55.24012Z",
     "iopub.status.busy": "2021-12-28T18:54:55.239793Z",
     "iopub.status.idle": "2021-12-28T18:54:55.493829Z",
     "shell.execute_reply": "2021-12-28T18:54:55.49307Z",
     "shell.execute_reply.started": "2021-12-28T18:54:55.240083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Décomposition de notre jeu de données en ensemble d'entrainement,de validation et de test \n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_train,df_train.label, test_size = test_ratio)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = val_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:54:55.495409Z",
     "iopub.status.busy": "2021-12-28T18:54:55.494992Z",
     "iopub.status.idle": "2021-12-28T18:54:55.501338Z",
     "shell.execute_reply": "2021-12-28T18:54:55.500668Z",
     "shell.execute_reply.started": "2021-12-28T18:54:55.495369Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:54:55.503234Z",
     "iopub.status.busy": "2021-12-28T18:54:55.502436Z",
     "iopub.status.idle": "2021-12-28T18:54:55.514537Z",
     "shell.execute_reply": "2021-12-28T18:54:55.513557Z",
     "shell.execute_reply.started": "2021-12-28T18:54:55.503194Z"
    }
   },
   "outputs": [],
   "source": [
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:54:55.517062Z",
     "iopub.status.busy": "2021-12-28T18:54:55.516412Z",
     "iopub.status.idle": "2021-12-28T18:54:55.521362Z",
     "shell.execute_reply": "2021-12-28T18:54:55.520396Z",
     "shell.execute_reply.started": "2021-12-28T18:54:55.517019Z"
    }
   },
   "outputs": [],
   "source": [
    "s_accuracy= []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:54:55.523871Z",
     "iopub.status.busy": "2021-12-28T18:54:55.523231Z",
     "iopub.status.idle": "2021-12-28T18:55:49.079182Z",
     "shell.execute_reply": "2021-12-28T18:55:49.078475Z",
     "shell.execute_reply.started": "2021-12-28T18:54:55.523831Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier1 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "#training the model\n",
    "classifier1.fit(X_train,Y_train)\n",
    "\n",
    "#score\n",
    "score1 = classifier1.score(X_val,Y_val)\n",
    "s_accuracy.append(score1)\n",
    "print(\"Accuracy:\", score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:55:49.081176Z",
     "iopub.status.busy": "2021-12-28T18:55:49.080704Z",
     "iopub.status.idle": "2021-12-28T18:55:49.100577Z",
     "shell.execute_reply": "2021-12-28T18:55:49.099769Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.081138Z"
    }
   },
   "outputs": [],
   "source": [
    "# predicting val set results\n",
    "Ypred1 = classifier1.predict(X_val)\n",
    "Ypred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:55:49.101911Z",
     "iopub.status.busy": "2021-12-28T18:55:49.101678Z",
     "iopub.status.idle": "2021-12-28T18:55:49.576748Z",
     "shell.execute_reply": "2021-12-28T18:55:49.57607Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.101877Z"
    }
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "plot_confusion_matrix(classifier1, X_val,Y_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:55:49.578185Z",
     "iopub.status.busy": "2021-12-28T18:55:49.577945Z",
     "iopub.status.idle": "2021-12-28T18:55:49.792235Z",
     "shell.execute_reply": "2021-12-28T18:55:49.791469Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.57815Z"
    }
   },
   "outputs": [],
   "source": [
    "#metrics\n",
    "Ypred_proba1 = classifier1.predict_proba(X_val)[::,1]\n",
    "fpr1, tpr1, _ = roc_curve(Y_val,  Ypred_proba1)\n",
    "\n",
    "#ROC curve\n",
    "plt.plot(fpr1,tpr1,'m')\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:57:42.275488Z",
     "iopub.status.busy": "2021-12-28T18:57:42.274919Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier2 = SVC(kernel='linear',probability=True)\n",
    "classifier2.fit(X_train,Y_train)\n",
    "\n",
    " #score\n",
    "score2 = classifier2.score(X_val,Y_val)\n",
    "print(\"Accuracy:\", score2)\n",
    "s_accuracy.append(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting val set results\n",
    "Ypred2 = classifier2.predict(X_val)\n",
    "Ypred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "plot_confusion_matrix(classifier2, X_val,Y_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "Ypred_proba2 = classifier2.predict_proba(X_val)[::,1]\n",
    "fpr2, tpr2, _ = metrics.roc_curve(Y_val,  Ypred_proba2)\n",
    "\n",
    "#ROC curve\n",
    "plt.plot(fpr2,tpr2)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:56:36.27446Z",
     "iopub.status.busy": "2021-12-28T18:56:36.274014Z",
     "iopub.status.idle": "2021-12-28T18:56:36.435555Z",
     "shell.execute_reply": "2021-12-28T18:56:36.434806Z",
     "shell.execute_reply.started": "2021-12-28T18:56:36.274421Z"
    }
   },
   "outputs": [],
   "source": [
    " \n",
    "classifier3 = MultinomialNB().fit(X_train,Y_train)\n",
    " \n",
    "#score\n",
    "score3 = classifier3.score(X_val, Y_val)\n",
    "s_accuracy.append(score3)\n",
    "print(\"Accuracy:\", score3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:56:36.750724Z",
     "iopub.status.busy": "2021-12-28T18:56:36.750281Z",
     "iopub.status.idle": "2021-12-28T18:56:36.773166Z",
     "shell.execute_reply": "2021-12-28T18:56:36.772505Z",
     "shell.execute_reply.started": "2021-12-28T18:56:36.750686Z"
    }
   },
   "outputs": [],
   "source": [
    "# predicting test set results\n",
    "Ypred3 = classifier3.predict(X_val)\n",
    "Ypred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:56:37.633785Z",
     "iopub.status.busy": "2021-12-28T18:56:37.633507Z",
     "iopub.status.idle": "2021-12-28T18:56:38.274198Z",
     "shell.execute_reply": "2021-12-28T18:56:38.273499Z",
     "shell.execute_reply.started": "2021-12-28T18:56:37.633752Z"
    }
   },
   "outputs": [],
   "source": [
    "#  confusion matrix\n",
    "plot_confusion_matrix(classifier3, X_val,Y_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:57:18.644504Z",
     "iopub.status.busy": "2021-12-28T18:57:18.644251Z",
     "iopub.status.idle": "2021-12-28T18:57:18.872443Z",
     "shell.execute_reply": "2021-12-28T18:57:18.871771Z",
     "shell.execute_reply.started": "2021-12-28T18:57:18.644476Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "#metrics\n",
    "Ypred_proba3 = classifier3.predict_proba(X_val)[::,1]\n",
    "fpr3, tpr3, _ = roc_curve(Y_val,  Ypred_proba3)\n",
    "\n",
    "#ROC curve\n",
    "plt.plot(fpr3,tpr3)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:57:21.526853Z",
     "iopub.status.busy": "2021-12-28T18:57:21.526376Z",
     "iopub.status.idle": "2021-12-28T18:57:21.566457Z",
     "shell.execute_reply": "2021-12-28T18:57:21.565458Z",
     "shell.execute_reply.started": "2021-12-28T18:57:21.526812Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = [\"Logistic regression\", \"SVM\", \"Naive Bayes\"]\n",
    "d = {'Accuracy': s_accuracy} \n",
    "\n",
    "sd = pd.DataFrame(s_accuracy, index=[model_name[i] for i in range(len(model_name))] ) \n",
    "sd = sd.rename(columns={0: \"Score\"})\n",
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T18:57:34.924212Z",
     "iopub.status.busy": "2021-12-28T18:57:34.92397Z",
     "iopub.status.idle": "2021-12-28T18:57:34.955991Z",
     "shell.execute_reply": "2021-12-28T18:57:34.954365Z",
     "shell.execute_reply.started": "2021-12-28T18:57:34.924185Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = sd.idxmax().values[0]\n",
    "score = clf.score(X_test)\n",
    "print(\"Le classifier final est:\"+clf)\n",
    "print(\"Le score obtenu = \"+str('%.2f'%score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.913725Z",
     "iopub.status.idle": "2021-12-28T18:55:49.914488Z",
     "shell.execute_reply": "2021-12-28T18:55:49.914275Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.91425Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(model,nepch,bsize):\n",
    "    \"\"\"\n",
    "    Training the neural network\n",
    "    @params:\n",
    "            - model: neural network\n",
    "            - npech: number of epochs\n",
    "            - bsize: batch size\n",
    "    @return: \n",
    "            history of neural network\n",
    "    \"\"\"\n",
    "    early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "    num_epochs = nepch\n",
    "    batch_size = bsize\n",
    "    with tf.device('/gpu:0'): # remove this line if not using Kaggle gpu\n",
    "        history = model.fit(com_tr_seq, \n",
    "                            lab_tr, \n",
    "                            epochs=num_epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_split=0.2,\n",
    "                            callbacks = [early],\n",
    "                            verbose=1)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.915727Z",
     "iopub.status.idle": "2021-12-28T18:55:49.916573Z",
     "shell.execute_reply": "2021-12-28T18:55:49.916369Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.916344Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_acc_loss(history):\n",
    "    \"\"\"\n",
    "    Plot accuracy and loss of a model\n",
    "    @params:\n",
    "            - history: history of the model\n",
    "    @return:\n",
    "            plots\n",
    "    \"\"\"\n",
    "    fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "    l = list(history.history.keys()\n",
    "    # accuracy plot\n",
    "    ax[0].plot(history.history[l[0]])\n",
    "    ax[0].plot(history.history[l[2]])\n",
    "    ax[0].set_title('model accuracy')\n",
    "    ax[0].set_ylabel('accuracy')\n",
    "    ax[0].set_xlabel('epoch')\n",
    "    ax[0].legend(['train', 'test'], loc='upper left')\n",
    "    # loss plot\n",
    "    ax[1].plot(history.history[l[1]])\n",
    "    ax[1].plot(history.history[l[3]])\n",
    "    ax[1].set_title('model loss')\n",
    "    ax[1].set_ylabel('loss')\n",
    "    ax[1].set_xlabel('epoch')\n",
    "    ax[1].legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.917649Z",
     "iopub.status.idle": "2021-12-28T18:55:49.91816Z",
     "shell.execute_reply": "2021-12-28T18:55:49.917953Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.917928Z"
    }
   },
   "outputs": [],
   "source": [
    "def predicted_label(model):\n",
    "    \"\"\"\n",
    "    Compute predictions\n",
    "    @params:\n",
    "            - model: neural network model\n",
    "    @return:\n",
    "            - list of prediction \n",
    "    \"\"\"\n",
    "    pred = model.predict(com_test_seq)\n",
    "    lab_pred = []\n",
    "    for i in pred:\n",
    "        if i>0.5:\n",
    "            lab_pred.append(1)\n",
    "        else:\n",
    "            lab_pred.append(0)\n",
    "    return lab_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.919508Z",
     "iopub.status.idle": "2021-12-28T18:55:49.920432Z",
     "shell.execute_reply": "2021-12-28T18:55:49.920219Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.920194Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting data : train and test set\n",
    "com_tr,com_test, lab_tr,lab_test = train_test_split(df_train['comment'],df_train['label'],test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.921699Z",
     "iopub.status.idle": "2021-12-28T18:55:49.922227Z",
     "shell.execute_reply": "2021-12-28T18:55:49.922027Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.922003Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cm(model):\n",
    "    pred = model.predict(com_test_seq)\n",
    "    lab_pred = predicted_label(model)\n",
    "    cm = confusion_matrix(lab_test,lab_pred)  \n",
    "    sn.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.923304Z",
     "iopub.status.idle": "2021-12-28T18:55:49.923857Z",
     "shell.execute_reply": "2021-12-28T18:55:49.923655Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.92363Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(model):\n",
    "    pred = model.predict(com_test_seq)\n",
    "    lab_pred = predicted_label(model)\n",
    "    # false and true positive rates\n",
    "    fpr,tpr,_ = roc_curve(lab_test,lab_pred)\n",
    "    # area under roc curve\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #ROC curve\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr,tpr,color=\"darkorange\",lw=lw,label=\"ROC curve (area = %0.2f)\" % roc_auc,)\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver operating characteristic example\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_roc(models):\n",
    "    fig,ax = plt.subplots()\n",
    "    for model in models:\n",
    "        pred = model.predict(com_test_seq)\n",
    "        lab_pred = predicted_label(model)\n",
    "        # false and true positive rates\n",
    "        fpr,tpr,_ = roc_curve(lab_test,lab_pred)\n",
    "        # area under roc curve\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        #ROC curve\n",
    "        lw = 2\n",
    "        i=1\n",
    "        ax.plot(fpr,tpr,lw=lw,label='model'+str(i))\n",
    "        i+=1\n",
    "    ax.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(\"Receiver operating characteristic\")\n",
    "    ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.924928Z",
     "iopub.status.idle": "2021-12-28T18:55:49.925468Z",
     "shell.execute_reply": "2021-12-28T18:55:49.925257Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.925234Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Pretrained Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.926524Z",
     "iopub.status.idle": "2021-12-28T18:55:49.927068Z",
     "shell.execute_reply": "2021-12-28T18:55:49.926871Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.926847Z"
    }
   },
   "outputs": [],
   "source": [
    "tok = Tokenizer()\n",
    "tok.fit_on_texts(com_tr)\n",
    "# text ---> integer sequence\n",
    "com_tr_seq  = tok.texts_to_sequences(com_tr) \n",
    "com_test_seq = tok.texts_to_sequences(com_test)\n",
    "\n",
    "# integer sequences --> integer sequences with same length\n",
    "com_tr_seq  = pad_sequences(com_tr_seq, maxlen=100)\n",
    "com_test_seq = pad_sequences(com_test_seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.928128Z",
     "iopub.status.idle": "2021-12-28T18:55:49.928688Z",
     "shell.execute_reply": "2021-12-28T18:55:49.928467Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.928444Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index = tok.word_index\n",
    "print(\"unique tokens - \",len(word_index))\n",
    "vocab_size = len(word_index) + 1\n",
    "print('vocab size -', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1: Bidirectional LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.929751Z",
     "iopub.status.idle": "2021-12-28T18:55:49.930278Z",
     "shell.execute_reply": "2021-12-28T18:55:49.930077Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.930053Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "model1= Sequential()\n",
    "#input layer/ embedding layer\n",
    "model1.add(Embedding(vocab_size, embedding_dim, input_length=100))\n",
    "#bidirectional lstm layer\n",
    "model1.add(Bidirectional(LSTM(128)))\n",
    "#fc layers\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Flatten())\n",
    "#output layer\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "# compiling model\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print('Summary of the built model:')\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.931321Z",
     "iopub.status.idle": "2021-12-28T18:55:49.93188Z",
     "shell.execute_reply": "2021-12-28T18:55:49.931676Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.931652Z"
    }
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "hist1 = training(model1,5,64)\n",
    "# evaluating the model \n",
    "acc1= model1.evaluate(com_test_seq,lab_test)\n",
    "print(\"Accuracy\")\n",
    "accuracy.append(acc1[1])\n",
    "acc1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.932928Z",
     "iopub.status.idle": "2021-12-28T18:55:49.933468Z",
     "shell.execute_reply": "2021-12-28T18:55:49.933257Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.933233Z"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy and loss\n",
    "plot_acc_loss(hist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.934529Z",
     "iopub.status.idle": "2021-12-28T18:55:49.935064Z",
     "shell.execute_reply": "2021-12-28T18:55:49.934866Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.934842Z"
    }
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "plot_cm(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.936122Z",
     "iopub.status.idle": "2021-12-28T18:55:49.936686Z",
     "shell.execute_reply": "2021-12-28T18:55:49.936473Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.936449Z"
    }
   },
   "outputs": [],
   "source": [
    "# roc curve\n",
    "plot_roc_curve(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model 2: LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.937739Z",
     "iopub.status.idle": "2021-12-28T18:55:49.938265Z",
     "shell.execute_reply": "2021-12-28T18:55:49.938065Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.938041Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "#input layer\n",
    "model2.add(Embedding(vocab_size, embedding_dim, input_length=100))\n",
    "#lstm layer\n",
    "model2.add(LSTM(64, dropout=0.5))\n",
    "#fc layer\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "#output layer\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "#compiling model\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print('Summary of the built model:')\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.939325Z",
     "iopub.status.idle": "2021-12-28T18:55:49.939881Z",
     "shell.execute_reply": "2021-12-28T18:55:49.939679Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.939654Z"
    }
   },
   "outputs": [],
   "source": [
    "hist2 = training(model2,5,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.940926Z",
     "iopub.status.idle": "2021-12-28T18:55:49.941462Z",
     "shell.execute_reply": "2021-12-28T18:55:49.941252Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.941228Z"
    }
   },
   "outputs": [],
   "source": [
    "acc2= model2.evaluate(com_test_seq,lab_test)\n",
    "accuracy.append(acc2[1])\n",
    "print(\"Accuracy\")\n",
    "acc2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.942513Z",
     "iopub.status.idle": "2021-12-28T18:55:49.943054Z",
     "shell.execute_reply": "2021-12-28T18:55:49.942856Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.942832Z"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy and loss\n",
    "plot_acc_loss(hist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.944114Z",
     "iopub.status.idle": "2021-12-28T18:55:49.944664Z",
     "shell.execute_reply": "2021-12-28T18:55:49.94445Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.944426Z"
    }
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "plot_cm(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.945719Z",
     "iopub.status.idle": "2021-12-28T18:55:49.946248Z",
     "shell.execute_reply": "2021-12-28T18:55:49.946049Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.946025Z"
    }
   },
   "outputs": [],
   "source": [
    "# roc curve\n",
    "plot_roc_curve(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Pretrained Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Glove**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.947286Z",
     "iopub.status.idle": "2021-12-28T18:55:49.947834Z",
     "shell.execute_reply": "2021-12-28T18:55:49.94764Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.947603Z"
    }
   },
   "outputs": [],
   "source": [
    "#upload the pretrained word embedding\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.948882Z",
     "iopub.status.idle": "2021-12-28T18:55:49.949425Z",
     "shell.execute_reply": "2021-12-28T18:55:49.949218Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.949194Z"
    }
   },
   "outputs": [],
   "source": [
    "#unzip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.950463Z",
     "iopub.status.idle": "2021-12-28T18:55:49.950999Z",
     "shell.execute_reply": "2021-12-28T18:55:49.950799Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.950775Z"
    }
   },
   "outputs": [],
   "source": [
    "#choosing the dimension, here we chose 300\n",
    "glove_input_file = 'glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.952039Z",
     "iopub.status.idle": "2021-12-28T18:55:49.952567Z",
     "shell.execute_reply": "2021-12-28T18:55:49.952373Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.95234Z"
    }
   },
   "outputs": [],
   "source": [
    "#we create a dictionary which contains a word and\n",
    "#its vector\n",
    "embeddings_dic={}\n",
    "f = open(glove_input_file)\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:],'float32')\n",
    "    embeddings_dic[word]=vector\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.953644Z",
     "iopub.status.idle": "2021-12-28T18:55:49.954171Z",
     "shell.execute_reply": "2021-12-28T18:55:49.953973Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.953949Z"
    }
   },
   "outputs": [],
   "source": [
    "# we build the embedding matrix for our text\n",
    "# we will use it in the embedding layer\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "h = 0\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_dic.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # word not found=> we put 0\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        h+=1\n",
    "\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.95533Z",
     "iopub.status.idle": "2021-12-28T18:55:49.955884Z",
     "shell.execute_reply": "2021-12-28T18:55:49.955683Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.95566Z"
    }
   },
   "outputs": [],
   "source": [
    "# building of the embedding layer\n",
    "embedding_layer = Embedding(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T10:58:02.187206Z",
     "iopub.status.busy": "2021-12-22T10:58:02.186917Z",
     "iopub.status.idle": "2021-12-22T10:58:03.010771Z",
     "shell.execute_reply": "2021-12-22T10:58:03.010026Z",
     "shell.execute_reply.started": "2021-12-22T10:58:02.187174Z"
    }
   },
   "source": [
    "**model 3: bidirectional lstm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.956958Z",
     "iopub.status.idle": "2021-12-28T18:55:49.957496Z",
     "shell.execute_reply": "2021-12-28T18:55:49.957285Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.957261Z"
    }
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "#input layer\n",
    "model3.add(embedding_layer)\n",
    "\n",
    "# 1st bi-LSTM layer\n",
    "model3.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
    "# 2nd bi-LSTM layer\n",
    "model3.add(Bidirectional(LSTM(64)))\n",
    "\n",
    "\n",
    "#FC layers\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "# compiling the model\n",
    "model3.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print('Summary of the built model:')\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.958537Z",
     "iopub.status.idle": "2021-12-28T18:55:49.959079Z",
     "shell.execute_reply": "2021-12-28T18:55:49.95888Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.958854Z"
    }
   },
   "outputs": [],
   "source": [
    "hist3 = training(model3,5,64)\n",
    "acc3=model3.evaluate(com_test_seq,lab_test)\n",
    "accuracy.append(acc3[1])\n",
    "print(\"Accuracy\")\n",
    "acc3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.960167Z",
     "iopub.status.idle": "2021-12-28T18:55:49.960848Z",
     "shell.execute_reply": "2021-12-28T18:55:49.96065Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.960625Z"
    }
   },
   "outputs": [],
   "source": [
    "#accuracy and loss\n",
    "plot_acc_loss(hist3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.9619Z",
     "iopub.status.idle": "2021-12-28T18:55:49.962435Z",
     "shell.execute_reply": "2021-12-28T18:55:49.962224Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.9622Z"
    }
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "plot_cm(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.963476Z",
     "iopub.status.idle": "2021-12-28T18:55:49.964015Z",
     "shell.execute_reply": "2021-12-28T18:55:49.963815Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.963791Z"
    }
   },
   "outputs": [],
   "source": [
    "#roc curve\n",
    "plot_roc_curve(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model 4: lstm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.965117Z",
     "iopub.status.idle": "2021-12-28T18:55:49.965663Z",
     "shell.execute_reply": "2021-12-28T18:55:49.965448Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.965424Z"
    }
   },
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "#input layer\n",
    "model4.add(embedding_layer)\n",
    "#lstm layer\n",
    "model4.add(LSTM(64, dropout=0.2))\n",
    "#fc layer\n",
    "model4.add(Dense(64, activation='relu'))\n",
    "#output layer\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "#compiling layer\n",
    "model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "print('Summary of the built model:')\n",
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.966769Z",
     "iopub.status.idle": "2021-12-28T18:55:49.967294Z",
     "shell.execute_reply": "2021-12-28T18:55:49.967096Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.967072Z"
    }
   },
   "outputs": [],
   "source": [
    "hist4 = training(model4,5,64)\n",
    "acc4 = model4.evaluate(com_test_seq,lab_test)\n",
    "accuracy.append(acc4[1])\n",
    "\n",
    "print(\"Accuracy\")\n",
    "acc4[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.96833Z",
     "iopub.status.idle": "2021-12-28T18:55:49.968881Z",
     "shell.execute_reply": "2021-12-28T18:55:49.968681Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.968657Z"
    }
   },
   "outputs": [],
   "source": [
    "#accuracy and loss\n",
    "plot_acc_loss(hist4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.969946Z",
     "iopub.status.idle": "2021-12-28T18:55:49.970481Z",
     "shell.execute_reply": "2021-12-28T18:55:49.970272Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.970248Z"
    }
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "plot_cm(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.971522Z",
     "iopub.status.idle": "2021-12-28T18:55:49.972058Z",
     "shell.execute_reply": "2021-12-28T18:55:49.97186Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.971836Z"
    }
   },
   "outputs": [],
   "source": [
    "#roc curve\n",
    "plot_roc_curve(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model 5: CNN+LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.973107Z",
     "iopub.status.idle": "2021-12-28T18:55:49.973655Z",
     "shell.execute_reply": "2021-12-28T18:55:49.973441Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.973418Z"
    }
   },
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "#input layer\n",
    "model5.add(embedding_layer)\n",
    "#convolutional layer\n",
    "model5.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model5.add(MaxPooling1D(pool_size=2))\n",
    "#lstm layer\n",
    "model5.add(LSTM(128))\n",
    "#output layer\n",
    "model5.add(Dense(1, activation='sigmoid'))\n",
    "#compiling the model \n",
    "model5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print('Summary of the built model:')\n",
    "print(model5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.974726Z",
     "iopub.status.idle": "2021-12-28T18:55:49.975255Z",
     "shell.execute_reply": "2021-12-28T18:55:49.975055Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.975032Z"
    }
   },
   "outputs": [],
   "source": [
    "hist5 = training(model5,5,64)\n",
    "accr5 = model5.evaluate(com_test_seq,lab_test)\n",
    "accuracy.append(acc5[1])\n",
    "\n",
    "print(\"Accuracy\")\n",
    "accr5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.976303Z",
     "iopub.status.idle": "2021-12-28T18:55:49.976869Z",
     "shell.execute_reply": "2021-12-28T18:55:49.976667Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.976642Z"
    }
   },
   "outputs": [],
   "source": [
    "#accuracy and loss\n",
    "plot_acc_loss(hist5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.977917Z",
     "iopub.status.idle": "2021-12-28T18:55:49.978459Z",
     "shell.execute_reply": "2021-12-28T18:55:49.978246Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.978222Z"
    }
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "plot_cm(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.979513Z",
     "iopub.status.idle": "2021-12-28T18:55:49.980049Z",
     "shell.execute_reply": "2021-12-28T18:55:49.97985Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.979827Z"
    }
   },
   "outputs": [],
   "source": [
    "#roc curve\n",
    "plot_roc_curve(model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.981099Z",
     "iopub.status.idle": "2021-12-28T18:55:49.981646Z",
     "shell.execute_reply": "2021-12-28T18:55:49.981432Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.981408Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name_ = [\"BiLSTM\", \"LSTM\", \"BiLSTM+Glove\",\"LSTM+Glove\",\"LSTM+CNN+Glove\"]\n",
    "d_ = {'Accuracy': accuracy} \n",
    "\n",
    "sd_ = pd.DataFrame(accuracy, index=[model_name_[i] for i in range(len(model_name_))] ) \n",
    "sd_ = sd_.rename(columns={0: \"Score\"})\n",
    "sd_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1,model2,model3,model4,model5]\n",
    "compare_roc(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.982696Z",
     "iopub.status.idle": "2021-12-28T18:55:49.983218Z",
     "shell.execute_reply": "2021-12-28T18:55:49.983022Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.982998Z"
    }
   },
   "outputs": [],
   "source": [
    "mod = sd_.idxmax().values[0]\n",
    "score_ = sd_.max().values[0]\n",
    "print(\"Le modèle final est:\"+mod)\n",
    "print(\"Le score obtenu = \"+str('%.2f'%score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.984275Z",
     "iopub.status.idle": "2021-12-28T18:55:49.984834Z",
     "shell.execute_reply": "2021-12-28T18:55:49.984631Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.984595Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_sarcasm(comment,model):\n",
    "    \"\"\"\n",
    "    Prediction if a comment is sarcastic or not\n",
    "    @param:\n",
    "            - comment: string representing the text contained in the comment\n",
    "            - model: model used for prediction\n",
    "    @return: \n",
    "            - string\n",
    "    \"\"\"\n",
    "    x = pd.DataFrame({\"comment\":[comment]})\n",
    "    cleaned =  cleaning_text(x)\n",
    "    tok.fit_on_texts(cleaned )\n",
    "    com_seq = tok.texts_to_sequences(cleaned )\n",
    "    com_pad = pad_sequences(com_seq, maxlen=100, padding='post')\n",
    "    pred = model.predict(com_pad)\n",
    "    pred*=100\n",
    "    #print(pred)\n",
    "    if pred[0,0]>=50: return \"It's a sarcasm!\" \n",
    "    else: return \"It's not a sarcasm.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.985878Z",
     "iopub.status.idle": "2021-12-28T18:55:49.986415Z",
     "shell.execute_reply": "2021-12-28T18:55:49.986203Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.98618Z"
    }
   },
   "outputs": [],
   "source": [
    "#no sarcasm\n",
    "predict_sarcasm(\"At least you tried your best\",model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-28T18:55:49.98746Z",
     "iopub.status.idle": "2021-12-28T18:55:49.987996Z",
     "shell.execute_reply": "2021-12-28T18:55:49.987798Z",
     "shell.execute_reply.started": "2021-12-28T18:55:49.987774Z"
    }
   },
   "outputs": [],
   "source": [
    "#sarcasm\n",
    "predict_sarcasm(\"I am busy right now, can I ignore you some other time?\",model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no sarcasm\n",
    "predict_sarcasm(\"OMG! How dare are u?\",model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sarcasm\n",
    "predict_sarcasm(\"oh politics, what fun it is\",model3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
